{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.cuda\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from wsi_dataset import WSIDataModule\n",
    "import yaml\n",
    "import importlib\n",
    "from models import MILModel,compute_c_index\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torchmetrics.functional as tf\n",
    "from models import compute_c_index,calculate_auc  \n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "from pytorch_lightning.strategies import DeepSpeedStrategy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import os\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices     \n",
    "from wsi_dataset import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Sampler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(fname):\n",
    "    with open(f\"/home/huruizhen/mil/configs/{fname}.yaml\", mode=\"r\",encoding='utf-8') as file:\n",
    "        yml = yaml.load(file, Loader=yaml.Loader)\n",
    "        return yml\n",
    "\n",
    "\n",
    "def get_obj_from_str(string, reload=False):     # string: \"models.report_only.report_only\"  \n",
    "    module, cls = string.rsplit(\".\", 1)  \n",
    "    if reload:\n",
    "        module_imp = importlib.import_module(module)\n",
    "        importlib.reload(module_imp)\n",
    "    return getattr(importlib.import_module(module, package=None), cls)\n",
    "\n",
    "class CoxSurvLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(CoxSurvLoss, self).__init__()\n",
    "\n",
    "    def forward(self, hazards, time, c):\n",
    "        '''\n",
    "        # hazards: risk value (log risk) from the model output\n",
    "        # time: event occurrence or observation time\n",
    "        # c: Whether the event occurred (1 means the event occurred, 0 means truncated)\n",
    "        '''\n",
    "\n",
    "        # This calculation credit to Travers Ching https://github.com/traversc/cox-nnet\n",
    "        # Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data\n",
    "        \n",
    "        hazards = hazards.squeeze()\n",
    "\n",
    "        current_batch_len = len(time)\n",
    "\n",
    "        R_mat = torch.zeros(\n",
    "            [current_batch_len, current_batch_len], \n",
    "            dtype=int, \n",
    "            device=hazards.device\n",
    "            )\n",
    "\n",
    "        for i in range(current_batch_len):\n",
    "            for j in range(current_batch_len):\n",
    "                R_mat[i,j] = time[j] >= time[i]\n",
    "                \n",
    "        theta = hazards.reshape(-1)\n",
    "        exp_theta = torch.exp(theta)\n",
    "        loss_cox = -torch.mean((theta - torch.log(torch.sum(exp_theta*R_mat, dim=1))) * c)\n",
    "\n",
    "        return loss_cox\n",
    "    \n",
    "def calculate_auc(logits, labels):\n",
    "    # Convert logits to probabilities using softmax\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    # Convert probabilities and labels to CPU tensors\n",
    "    probabilities = probabilities.cpu().detach().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    \n",
    "    num_classes = probabilities.shape[1]\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        # Binary classification case\n",
    "        unique_labels = np.unique(labels)\n",
    "        # print(f'unique_labels: {unique_labels}')\n",
    "        if len(unique_labels) == 2:\n",
    "            # Binary classification with two classes (0 and 1)\n",
    "            binary_probabilities = probabilities[:, 1]\n",
    "            auc = roc_auc_score(labels, binary_probabilities)  \n",
    "        else:\n",
    "            # Binary classification with more than two classes\n",
    "            print(f'*************There is only one real tag in the binary classification task, and the AUC cannot be calculated.**************')\n",
    "            auc = 0\n",
    "        \n",
    "    else:\n",
    "        # Multiclass case\n",
    "        aucs = []\n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) == 1 :\n",
    "            print(f'*************There is only one real tag in a multi-class task, and the AUC cannot be calculated. tag in the multiclass classification task, and the AUC cannot be calculated.**************')\n",
    "            auc = 0\n",
    "            return auc\n",
    "        else:\n",
    "            for i in unique_labels: \n",
    "                i = int(i)\n",
    "                binary_labels = (labels == i).astype(int)\n",
    "                class_probabilities = probabilities[:, i]\n",
    "                auc = roc_auc_score(binary_labels, class_probabilities)\n",
    "                aucs.append(auc)\n",
    "            auc = sum(aucs) / len(unique_labels)  \n",
    "    \n",
    "    return auc\n",
    "\n",
    "\n",
    "def compute_P_value(hazard_scores: torch.Tensor, labels:torch.Tensor, status:torch.Tensor) -> np.ndarray:  \n",
    "    from lifelines.statistics import logrank_test  \n",
    "\n",
    "    all_hazard_scores = hazard_scores.cpu().numpy()\n",
    "    all_hazard_ratios = np.exp(all_hazard_scores)\n",
    "    all_labels = labels.cpu().numpy()\n",
    "    all_status = status.cpu().numpy()\n",
    "    assert len(all_hazard_scores) == len(all_labels) == len(all_status)\n",
    "\n",
    "    # Divide high and low risk groups by median all_hazard_ratios\n",
    "    median_risk = np.median(all_hazard_scores)\n",
    "    high_risk_mask = all_hazard_scores > median_risk\n",
    "    low_risk_mask = ~high_risk_mask  # Reverse, indicating low risk\n",
    "\n",
    "    # Obtain HR in high and low risk groups\n",
    "    high_risk_HR = all_hazard_scores[high_risk_mask]\n",
    "    low_risk_HR = all_hazard_scores[low_risk_mask]\n",
    "\n",
    "    # Get indexes for high-risk groups\n",
    "    high_risk_indices = np.where(high_risk_mask)[0]\n",
    "    low_risk_indices = np.where(low_risk_mask)[0]\n",
    "\n",
    "    # Get the corresponding data by index\n",
    "    high_risk_labels = all_labels[high_risk_indices]\n",
    "    high_risk_status = all_status[high_risk_indices]\n",
    "\n",
    "    low_risk_labels = all_labels[low_risk_indices]\n",
    "    low_risk_status = all_status[low_risk_indices]\n",
    "\n",
    "\n",
    "    # 4.Calculate p_value\n",
    "    results = logrank_test(\n",
    "        durations_A=high_risk_labels,\n",
    "        durations_B=low_risk_labels,\n",
    "        event_observed_A=high_risk_status,\n",
    "        event_observed_B=low_risk_status,\n",
    "    )\n",
    "    p_value = results.p_value\n",
    "    return p_value\n",
    "\n",
    "\n",
    "# seed everything\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)   # Setting python hash seed\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch.set_deterministic(True)  # torch < 1.8\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)  # torch >= 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bootstrap to calculate AUC and C-index 95% Confidence Interval\n",
    "def bootstrap_auc(y_true: np.ndarray | torch.Tensor | list, \n",
    "                  y_prob: np.ndarray | torch.Tensor | list, \n",
    "                  n_bootstrap: int = 3000, \n",
    "                  alpha: float = 0.05) -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Compute the 95% CI, auc_mean and auc_std using the Bootstrap method.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (array-like): True labels. Can be a numpy array, torch tensor, or list.\n",
    "        y_prob (array-like): Predicted probabilities. [n_samples, n_classes] Can be a numpy array, torch tensor, or list.\n",
    "        n_bootstrap (int, optional): Number of bootstrap resampling iterations. Default is 3000.\n",
    "        alpha (float, optional): Significance level for confidence interval. Default is 0.05 (corresponding to 95% CI).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - auc_mean (float): Mean AUC for binary, Mean Macro-AUC for Multiclasses from bootstrap samples.\n",
    "            - ci_lower (float): Lower bound of the 95% confidence interval.\n",
    "            - ci_upper (float): Upper bound of the 95% confidence interval.\n",
    "            - auc_std (float): Standard deviation of AUC values from bootstrap samples.\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays if they are not already\n",
    "    def to_numpy(x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.cpu().numpy()  # Move tensor to CPU and convert to np.ndarray\n",
    "        return np.array(x) if isinstance(x, list) else x\n",
    "\n",
    "    y_true = to_numpy(y_true)\n",
    "    if len(np.unique(y_true)) <= 1:\n",
    "        raise ValueError(\"y_true contains only one unique class. At least two classes are required for AUC computation.\")\n",
    "    y_true_numbers = np.unique(y_true)\n",
    "    y_prob = to_numpy(y_prob)\n",
    "    n_classes = y_prob.shape[1]\n",
    "    n_samples = len(y_true)\n",
    "\n",
    "    auc_values = []\n",
    "    if n_classes == 2:\n",
    "        # Binary classification\n",
    "        assert len(np.unique(y_true)) == 2, \"y_true should contain only two unique classes for binary classification.\"\n",
    "        for _ in range(n_bootstrap):\n",
    "            indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "            if len(np.unique(y_true[indices])) == 2:\n",
    "                auc = roc_auc_score(y_true[indices], y_prob[indices][:, 1])\n",
    "                auc_values.append(auc)\n",
    "\n",
    "    elif n_classes > 2:  # Multiclass classification\n",
    "        if len(np.unique(y_true)) < n_classes:\n",
    "            # Handle the case where len(np.unique(y_true)) < n_classes\n",
    "            # Calculate AUC for each existing class and average them\n",
    "            existing_classes = np.unique(y_true)\n",
    "            for _ in range(n_bootstrap):\n",
    "                indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "                class_aucs = []\n",
    "                for cls in existing_classes:\n",
    "                    cls = int(cls)\n",
    "                    binary_y_true = (y_true[indices] == cls).astype(int)  # Convert to binary classification for the current class\n",
    "                    if len(np.unique(binary_y_true)) == 2:  # Ensure both classes are present\n",
    "                        auc = roc_auc_score(binary_y_true, y_prob[indices][:, cls])\n",
    "                        class_aucs.append(auc)\n",
    "                if len(class_aucs) > 0:\n",
    "                    auc_values.append(np.mean(class_aucs))\n",
    "\n",
    "        elif len(np.unique(y_true)) == n_classes:\n",
    "            # Handle the case where len(np.unique(y_true)) == n_classes. Use 'Macro-AUC' to calculate AUC for each class and average them\n",
    "            for _ in range(n_bootstrap):\n",
    "                indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "                if len(np.unique(y_true[indices])) == n_classes:\n",
    "                    auc = roc_auc_score(y_true[indices], y_prob[indices], average='macro', multi_class='ovr')\n",
    "                    auc_values.append(auc)\n",
    "    \n",
    "    if len(auc_values) == 0:\n",
    "        raise ValueError(\"Bootstrap did not generate valid samples. This may occur if the data contains only one class or is highly imbalanced.\")\n",
    "    \n",
    "    auc_values = np.array(auc_values)\n",
    "    \n",
    "    # Calculate 95% CI and mean, standard deviation\n",
    "    ci_lower = np.percentile(auc_values, 100 * alpha / 2)  # Lower bound of CI\n",
    "    ci_upper = np.percentile(auc_values, 100 * (1 - alpha / 2))  # Upper bound of CI\n",
    "    auc_mean = np.mean(auc_values)  # Mean AUC\n",
    "    auc_std = np.std(auc_values)  # Standard deviation of AUC values\n",
    "    \n",
    "    return auc_mean, ci_lower, ci_upper, auc_std, auc_values\n",
    "\n",
    "\n",
    "# Calculate C-index, Concordance Index\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "def bootstrap_cindex(risks: np.ndarray | torch.Tensor | list,\n",
    "                     pfs: np.ndarray | torch.Tensor | list, \n",
    "                     status: np.ndarray | torch.Tensor | list, \n",
    "                     n_bootstrap: int = 3000,\n",
    "                     alpha: float = 0.05) -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Compute the 95% CI, Cindex_mean and Cindex_std using the Bootstrap method.\n",
    "\n",
    "    Parameters:\n",
    "        risks (array-like): Predicted risks. Can be a numpy array, torch tensor, or list.\n",
    "        pfs (array-like): True survival times. Can be a numpy array, torch tensor, or list.\n",
    "        status (array-like): Event indicators (1 if event occurred, 0 otherwise). Can be a numpy array, torch tensor, or list.\n",
    "        n_bootstrap (int, optional): Number of bootstrap resampling iterations. Default is 3000.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - cindex_mean (float): Mean C-index from bootstrap samples.\n",
    "            - ci_lower (float): Lower bound of the 95% confidence interval.\n",
    "            - ci_upper (float): Upper bound of the 95% confidence interval.\n",
    "            - cindex_std (float): Standard deviation of C-index values from bootstrap samples.\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays if they are not already\n",
    "    def to_numpy(x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.cpu().numpy()  # Move tensor to CPU and convert to np.ndarray\n",
    "        return np.array(x) if isinstance(x, list) else x\n",
    "\n",
    "    risks = to_numpy(risks)\n",
    "    pfs = to_numpy(pfs)\n",
    "    status = to_numpy(status)\n",
    "\n",
    "    cindex_values = []\n",
    "    \n",
    "    # Bootstrap resampling\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(len(risks), size=len(risks), replace=True)\n",
    "        if len(np.unique(status[indices])) > 1:\n",
    "            status = status.astype(bool)\n",
    "            cindex = concordance_index_censored(status[indices], pfs[indices], np.squeeze(risks[indices]))[0]\n",
    "            cindex_values.append(cindex)\n",
    "\n",
    "    if len(cindex_values) == 0:\n",
    "        raise ValueError(\"Bootstrap did not generate valid samples. This may occur if the data contains only one class or is highly imbalanced.\")\n",
    "    \n",
    "    cindex_values = np.array(cindex_values)\n",
    "\n",
    "    # Calculate 95% CI and mean, standard deviation\n",
    "    ci_lower = np.percentile(cindex_values, 100 * alpha / 2)  # Lower bound of CI\n",
    "    ci_upper = np.percentile(cindex_values, 100 * (1 - alpha / 2))  # Upper bound of CI\n",
    "    cindex_mean = np.mean(cindex_values)  # Mean C-index\n",
    "    cindex_std = np.std(cindex_values)  # Standard deviation of C-index values\n",
    "    return cindex_mean, ci_lower, ci_upper, cindex_std, cindex_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk Group,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_hazard_level_MultiModal/hazard_level/seed493/five_fold.csv\n",
      "all_labels: torch.Size([93]), all_probs: torch.Size([93, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.7858 (0.7017--0.8647)\n",
      "\n",
      "\n",
      "subtype,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_subtype_MultiModal/subtype/seed648/five_fold.csv\n",
      "all_labels: torch.Size([170]), all_probs: torch.Size([170, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.9698 (0.9499--0.9865)\n",
      "\n",
      "\n",
      "shimada,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_shimada_MultiModal/shimada/seed739/five_fold.csv\n",
      "all_labels: torch.Size([181]), all_probs: torch.Size([181, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8357 (0.7720--0.8939)\n",
      "\n",
      "\n",
      "mki,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_mki_MultiModal/mki/seed526/five_fold.csv\n",
      "all_labels: torch.Size([127]), all_probs: torch.Size([127, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8235 (0.7634--0.8775)\n",
      "\n",
      "\n",
      "alk,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_alk_MultiModal/alk/seed648/five_fold.csv\n",
      "all_labels: torch.Size([126]), all_probs: torch.Size([126, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8513 (0.7725--0.9188)\n",
      "\n",
      "\n",
      "cmyc,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_cmyc_MultiModal/cmyc/seed255/five_fold.csv\n",
      "all_labels: torch.Size([123]), all_probs: torch.Size([123, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8089 (0.7293--0.8794)\n",
      "\n",
      "\n",
      "nmyc,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_nmyc_MultiModal/nmyc/seed526/five_fold.csv\n",
      "all_labels: torch.Size([83]), all_probs: torch.Size([83, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8721 (0.7778--0.9472)\n",
      "\n",
      "\n",
      "p36,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_p36_MultiModal/p36/seed526/five_fold.csv\n",
      "all_labels: torch.Size([38]), all_probs: torch.Size([38, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.7623 (0.5882--0.9028)\n",
      "\n",
      "\n",
      "q23,mode:best\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_cls_q23_MultiModal/q23/seed526/five_fold.csv\n",
      "all_labels: torch.Size([38]), all_probs: torch.Size([38, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.6148 (0.4178--0.7972)\n",
      "\n",
      "\n",
      "pfs,mode:mean\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_reg_pfs_MultiModal/pfs/seed526/five_fold.csv\n",
      "c_index:0.7812,p_value:0.0\n",
      "bootstrap_cindex_mean & CI:\n",
      "0.7825 (0.6979--0.8597), 0.0\n",
      "\n",
      "\n",
      "os,mode:mean\n",
      "csv_path: /home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/config_reg_os_MultiModal/os/seed381/five_fold.csv\n",
      "c_index:0.7085,p_value:0.0041\n",
      "bootstrap_cindex_mean & CI:\n",
      "0.7075 (0.5957--0.8082), 0.0041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! Inetrnal Test Set,NEVA multi-modal\n",
    "all_top_entries = []\n",
    "MultiModal_list=['config_cls_hazard_level_MultiModal','config_cls_subtype_MultiModal',\n",
    "                 'config_cls_shimada_MultiModal','config_cls_mki_MultiModal',\n",
    "                 'config_cls_alk_MultiModal','config_cls_cmyc_MultiModal',\n",
    "                 'config_cls_nmyc_MultiModal','config_cls_p36_MultiModal','config_cls_q23_MultiModal',\n",
    "                 'config_reg_pfs_MultiModal','config_reg_os_MultiModal',]\n",
    "\n",
    "for fname in MultiModal_list:\n",
    "    config_yaml = read_config(fname)\n",
    "    original_csv = config_yaml['Data']['dataframe']  \n",
    "    proj_name = config_yaml['Data']['label_name']   \n",
    "    if proj_name in ['pfs','os']:\n",
    "        mode = 'mean'\n",
    "        print(f'\\n{proj_name},mode:{mode}')\n",
    "    else:\n",
    "        mode = 'best'\n",
    "        if proj_name == 'hazard_level':\n",
    "            print(f'\\nRisk Group,mode:{mode}')\n",
    "        else:\n",
    "            print(f'\\n{proj_name},mode:{mode}')\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_gpus = 1\n",
    "    dist = False \n",
    "    seed_chosen,fold_chosen = config_yaml['seed&fold']\n",
    "\n",
    "    seed_list = [42,184,762,381,493,526,307, 648, 255, 739]\n",
    "    for seed in seed_list:\n",
    "        if seed != seed_chosen:\n",
    "            continue\n",
    "\n",
    "        wts_dir = f\"/home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/{fname}/{proj_name}/seed{seed}\"\n",
    "        csv_path = f\"{wts_dir}/five_fold.csv\"   \n",
    "        all_data_csv_path = f\"/home/huruizhen/mil/workspace/splits/{proj_name}.csv\"\n",
    "        print(f\"csv_path: {csv_path}\")\n",
    "\n",
    "        assert os.path.exists(csv_path), f\"CSV file not found: {csv_path}\"\n",
    "        assert os.path.exists(all_data_csv_path), f\"CSV file not found: {all_data_csv_path}\"\n",
    "        df_all_data = pd.read_csv(all_data_csv_path)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        metric = []\n",
    "        for fold in range(5):\n",
    "            if fold != fold_chosen:\n",
    "                continue\n",
    "\n",
    "            test_df = df[df['fold'] == fold].copy()\n",
    "            test_df_case_ids = test_df['case_id'].tolist()\n",
    "            train_df = df[df['fold'] != fold].copy()\n",
    "            train_df_case_ids = train_df['case_id'].tolist()\n",
    "            os.makedirs(f\"/home/huruizhen/mil/workspace/独立测试集/多中心测试/内部测试集/{proj_name}/\", exist_ok=True)\n",
    "\n",
    "            if proj_name not in ['pfs','os']:\n",
    "                if test_df[str(proj_name)].nunique() == 1:\n",
    "                    print(f'{proj_name}There is only one category, cannot calculate auc/cindex')\n",
    "                    continue\n",
    "             \n",
    "            patient_files = {}\n",
    "            for index, row_test in test_df.iterrows():\n",
    "                case_id = row_test['case_id']  \n",
    "                if case_id not in patient_files:\n",
    "                    patient_files[case_id] = []\n",
    "                patient_files[case_id].append(row_test['filename'])\n",
    "\n",
    "            training_all_df = pd.DataFrame()  \n",
    "            for index, row_train in train_df.iterrows():\n",
    "                case_id = row_train['case_id']  \n",
    "                for index, row_all in df_all_data.iterrows():\n",
    "                    if row_all['case_id'] == case_id:\n",
    "                        training_all_df = pd.concat([training_all_df, row_all.to_frame().T], ignore_index=True)\n",
    "\n",
    "            SAVE = False\n",
    "            if SAVE:\n",
    "                training_all_df.to_csv(f\"/home/huruizhen/mil/workspace/独立测试集/多中心测试/内部测试集/{proj_name}/train_seed{seed}_fold{fold}.csv\", index=False)\n",
    "                test_df.to_csv(f\"/home/huruizhen/mil/workspace/独立测试集/多中心测试/内部测试集/{proj_name}/test_seed{seed}_fold{fold}.csv\", index=False)\n",
    "\n",
    "\n",
    "            feature_dict = {}\n",
    "            for file_name in test_df['filename']:\n",
    "                file_path = '/home/huruizhen/多尺度特征/images_multisacle_2048/' + file_name\n",
    "                feature_dict[file_name[:-len('.pt')]] = file_path\n",
    "\n",
    "            patient_files = {str(k): [feature_dict[i[:-len('.pt')]] for i in v] for k, v in patient_files.items()}\n",
    "            patient_feature_vision = {case_id: [torch.load(file_name,map_location=device).unsqueeze(0).float() for file_name in file_list] for case_id, file_list in patient_files.items()}\n",
    "\n",
    "            test_df.drop_duplicates(subset=['case_id'], inplace=True)  \n",
    "            test_df.reset_index(drop=True, inplace=True) \n",
    "            test_df['case_id'] = test_df['case_id'].astype(str)  \n",
    "            if config_yaml['Data']['label_name'] in ['os','pfs']:\n",
    "                all_labels = torch.tensor(test_df['time'].values)\n",
    "                all_status = torch.tensor(test_df['status'].values)\n",
    "                all_case_id_label = {case_id : (torch.tensor(test_df[test_df['case_id']==case_id]['time'].tolist()),torch.tensor(test_df[test_df['case_id']==case_id]['status'].tolist())) for case_id,feature_list in patient_feature_vision.items()}\n",
    "            else:\n",
    "                all_labels = torch.tensor(test_df[config_yaml['Data']['label_name']].values)  \n",
    "                all_case_id_label = {case_id : torch.tensor(test_df[test_df['case_id']==case_id][config_yaml['Data']['label_name']].tolist()) for case_id,feature_list in patient_feature_vision.items()}\n",
    "            \n",
    "            patient_feature_report = {str(case_id):torch.load('/home/huruizhen/mil_dataset_1024/reports_1024/'+str(case_id)+'.pt',map_location=device).unsqueeze(dim=0).float() for case_id in test_df['case_id']}\n",
    "            assert len(patient_feature_vision.keys())==len(patient_feature_report.keys())\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                wts_path = f\"/home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/{fname}/{proj_name}/seed{seed}/fold_{fold}/fold_{fold}.pth\"\n",
    "                # print(f'seed：{seed} fold：{fold}\\n加载模型的路径是：{wts_path}')\n",
    "                wts = torch.load(wts_path)\n",
    "                save_path = None\n",
    "                model = MILModel(config_yaml, save_path=str(save_path)).to(device)\n",
    "                model.load_state_dict(wts,strict=True)\n",
    "                criterion = get_obj_from_str(config_yaml[\"Loss\"][\"name\"])(**config_yaml[\"Loss\"][\"params\"])\n",
    "                case_id_logits={}\n",
    "\n",
    "                for case_id,feature_list_vision in patient_feature_vision.items():  \n",
    "\n",
    "                    if case_id not in patient_feature_report:\n",
    "                        print(f\"{case_id} Not in the patient's pathological report\")\n",
    "                        print(patient_feature_report)\n",
    "                    feature_report = patient_feature_report[case_id].to(device)\n",
    "                    # print(feature_report.shape)\n",
    "                    logits = []\n",
    "                    for feature_vision in feature_list_vision:\n",
    "                        feature_vision = feature_vision.to(device)\n",
    "                        # print(case_id,feature_vision.shape)\n",
    "                        with torch.inference_mode():  \n",
    "                            logit, results_dict = model((feature_vision,feature_report))\n",
    "\n",
    "                        logits.append(logit)\n",
    "\n",
    "                    # print(logits)\n",
    "\n",
    "                    if mode == 'mean':\n",
    "                        case_id_logits[case_id]=torch.cat(logits,dim=0).mean(dim=0,keepdim=True)  # 同一个人的不同file获得的logit取平均\n",
    "                    # print(case_id_logits[case_id].shape)\n",
    "                    if mode == 'best':\n",
    "                        case_id_logits[case_id] = logits[0]\n",
    "                        best_logit = logits[0]\n",
    "                        if config_yaml['Data']['label_name'] in ['os','pfs']:\n",
    "                            label,status = all_case_id_label[case_id]\n",
    "                            label = label.long().to(device)\n",
    "                            status = status.long().to(device)\n",
    "                            criterion = CoxSurvLoss()\n",
    "                            best_crossentropy = criterion(logits[0].float(),label,status)\n",
    "                            for logit in logits[1:]:\n",
    "                                crossentropy = criterion(logit,label,status)\n",
    "                                if crossentropy <= best_crossentropy:\n",
    "                                    case_id_logits[case_id] = logit\n",
    "                        else:\n",
    "                            label = all_case_id_label[case_id].long().to(device)\n",
    "\n",
    "                            criterion = nn.CrossEntropyLoss()\n",
    "                            best_crossentropy = criterion(logits[0].float(),label)\n",
    "                            # print('交叉熵损失是：',best_crossentropy)\n",
    "                            for logit in logits[1:]:\n",
    "                                crossentropy = criterion(logit,label)\n",
    "                                # print(crossentropy)\n",
    "                                if crossentropy <= best_crossentropy:\n",
    "                                    case_id_logits[case_id] = logit\n",
    "                    # print(f\"case_id:{case_id},logits:{case_id_logits[case_id]},lebels:{all_case_id_label[case_id]}\")\n",
    "                del patient_feature_vision, patient_feature_report\n",
    "                all_logits = torch.cat([logits for case_id,logits in case_id_logits.items()],dim = 0)\n",
    "\n",
    "                if config_yaml['Data']['label_name'] in ['os','pfs']:\n",
    "\n",
    "                    risks_list = all_logits\n",
    "                    labels_list = all_labels\n",
    "                    status_list = all_status\n",
    "                    c_index =float(round(compute_c_index(risks_list, labels_list, status_list), 4))\n",
    "                    p_value = float(round(compute_P_value(risks_list, labels_list, status_list), 4))\n",
    "                    print(f'c_index:{c_index},p_value:{p_value}')\n",
    "                    metric.append(c_index)\n",
    "                    \n",
    "                    bootstrap_cindex_mean, ci_lower, ci_upper, cindex_std, cindex_values = bootstrap_cindex(risks_list, labels_list, status_list)\n",
    "                    print(f'bootstrap_cindex_mean & CI:\\n{bootstrap_cindex_mean:.4f} ({ci_lower:.4f}--{ci_upper:.4f}), {p_value}\\n')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    auc = float(round(calculate_auc(all_logits, all_labels), 4))\n",
    "                    # print(f'auc:{auc}')\n",
    "                    metric.append(auc)\n",
    "\n",
    "                    all_probs = torch.softmax(all_logits, dim=1)\n",
    "                    print(f\"all_labels: {all_labels.shape}, all_probs: {all_probs.shape}\")\n",
    "                    bootstrap_auc_mean, ci_lower, ci_upper, auc_std, auc_values = bootstrap_auc(all_labels, all_probs)\n",
    "                    print(f'bootstrap_auc_mean & CI:\\n{bootstrap_auc_mean:.4f} ({ci_lower:.4f}--{ci_upper:.4f})\\n')\n",
    "                # del patient_feature_vision\n",
    "                del model\n",
    "                del all_logits\n",
    "                del all_labels\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prospective test set, external PUFH, SCH, and GCI test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***************Cohorts：Prospective***************\n",
      "['config_cls_cmyc_MultiModal', 'config_cls_subtype_MultiModal', 'config_cls_hazard_level_MultiModal', 'config_cls_p36_MultiModal', 'config_cls_shimada_MultiModal', 'config_cls_nmyc_MultiModal', 'config_cls_mki_MultiModal', 'config_cls_alk_MultiModal', 'config_cls_q23_MultiModal']\n",
      "cmyc\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/cmyc.csv\n",
      "all_labels: torch.Size([59]), all_probs: torch.Size([59, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8756 (0.7673--0.9578)\n",
      "\n",
      "subtype\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/subtype.csv\n",
      "all_labels: torch.Size([67]), all_probs: torch.Size([67, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.9484 (0.9048--0.9835)\n",
      "\n",
      "Risk Group\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/hazard_level.csv\n",
      "all_labels: torch.Size([23]), all_probs: torch.Size([23, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8814 (0.7263--0.9898)\n",
      "\n",
      "1p36\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/p36.csv\n",
      "all_labels: torch.Size([33]), all_probs: torch.Size([33, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.7268 (0.5165--0.8981)\n",
      "\n",
      "shimada\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/shimada.csv\n",
      "all_labels: torch.Size([68]), all_probs: torch.Size([68, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8847 (0.7916--0.9595)\n",
      "\n",
      "nmyc\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/nmyc.csv\n",
      "all_labels: torch.Size([29]), all_probs: torch.Size([29, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "1.0000 (1.0000--1.0000)\n",
      "\n",
      "mki\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/mki.csv\n",
      "all_labels: torch.Size([63]), all_probs: torch.Size([63, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.9165 (0.8619--0.9622)\n",
      "\n",
      "alk\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/alk.csv\n",
      "all_labels: torch.Size([59]), all_probs: torch.Size([59, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.9034 (0.8103--0.9765)\n",
      "\n",
      "11q23\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验/q23.csv\n",
      "all_labels: torch.Size([32]), all_probs: torch.Size([32, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8637 (0.7100--0.9710)\n",
      "\n",
      "\n",
      "\n",
      "***************Cohorts：PUFH***************\n",
      "['config_cls_subtype_MultiModal', 'config_cls_hazard_level_MultiModal', 'config_cls_p36_MultiModal', 'config_cls_shimada_MultiModal', 'config_cls_nmyc_MultiModal', 'config_reg_pfs_MultiModal', 'config_reg_os_MultiModal', 'config_cls_mki_MultiModal', 'config_cls_q23_MultiModal']\n",
      "subtype\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/subtype.csv\n",
      "all_labels: torch.Size([48]), all_probs: torch.Size([48, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8546 (0.7690--0.9259)\n",
      "\n",
      "Risk Group\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/hazard_level.csv\n",
      "all_labels: torch.Size([45]), all_probs: torch.Size([45, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.6903 (0.5026--0.8747)\n",
      "\n",
      "1p36\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/p36.csv\n",
      "all_labels: torch.Size([17]), all_probs: torch.Size([17, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "1.0000 (1.0000--1.0000)\n",
      "\n",
      "shimada\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/shimada.csv\n",
      "all_labels: torch.Size([41]), all_probs: torch.Size([41, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.9164 (0.8097--0.9871)\n",
      "\n",
      "nmyc\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/nmyc.csv\n",
      "all_labels: torch.Size([40]), all_probs: torch.Size([40, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.7191 (0.4026--0.9446)\n",
      "\n",
      "pfs\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/pfs.csv\n",
      "c_index:0.7025,p_value:0.0074\n",
      "bootstrap_cindex_mean & CI:\n",
      "0.7092 (0.5366--0.8843), 0.0074\n",
      "\n",
      "os\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/os.csv\n",
      "c_index:0.8701,p_value:0.008\n",
      "bootstrap_cindex_mean & CI:\n",
      "0.8750 (0.7357--0.9811), 0.008\n",
      "\n",
      "mki\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/mki.csv\n",
      "all_labels: torch.Size([42]), all_probs: torch.Size([42, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8577 (0.7195--0.9627)\n",
      "\n",
      "11q23\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来/q23.csv\n",
      "q23There is only one category, cannot calculate auc/cindex\n",
      "\n",
      "\n",
      "***************Cohorts：SCH***************\n",
      "['config_cls_subtype_MultiModal', 'config_cls_shimada_MultiModal']\n",
      "subtype\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/深圳/subtype.csv\n",
      "all_labels: torch.Size([27]), all_probs: torch.Size([27, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.9684 (0.8972--1.0000)\n",
      "\n",
      "shimada\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/深圳/shimada.csv\n",
      "all_labels: torch.Size([27]), all_probs: torch.Size([27, 2])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.7829 (0.5926--0.9412)\n",
      "\n",
      "\n",
      "\n",
      "***************Cohorts：GCI***************\n",
      "['config_cls_subtype_MultiModal']\n",
      "subtype\n",
      "/home/huruizhen/mil/workspace/独立测试集/多中心测试/贵阳&cbtn&内蒙古/subtype.csv\n",
      "all_labels: torch.Size([19]), all_probs: torch.Size([19, 3])\n",
      "bootstrap_auc_mean & CI:\n",
      "0.8832 (0.6667--1.0000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prospective test set, external PUFH, SCH, and GCI test sets\n",
    "\n",
    "all_top_entries = []\n",
    "\n",
    "csv_dir_list = ['/home/huruizhen/mil/workspace/独立测试集/多中心测试/前瞻实验','/home/huruizhen/mil/workspace/独立测试集/多中心测试/北大附一合并起来',\n",
    "                '/home/huruizhen/mil/workspace/独立测试集/多中心测试/深圳',\n",
    "                '/home/huruizhen/mil/workspace/独立测试集/多中心测试/贵阳&cbtn&内蒙古',]\n",
    "\n",
    "for csv_dir in csv_dir_list:  \n",
    "    hospital_center = os.path.basename(csv_dir)\n",
    "    if hospital_center == '前瞻实验':\n",
    "        hospital_center = 'Prospective'\n",
    "    elif hospital_center == '北大附一合并起来':\n",
    "        hospital_center = 'PUFH'\n",
    "    elif hospital_center == '深圳':\n",
    "        hospital_center = 'SCH'\n",
    "    elif hospital_center == '贵阳&cbtn&内蒙古':\n",
    "        hospital_center = 'GCI'\n",
    "    print(f'\\n\\n***************Cohorts：{hospital_center}***************')\n",
    "    proj_name_list = [proj_name.replace('.csv','') for proj_name in os.listdir(csv_dir) if proj_name.endswith('.csv')]\n",
    "    MultiModal_list = []\n",
    "    for proj_name in proj_name_list:\n",
    "        if proj_name in ['pfs','os']:\n",
    "            MultiModal_list.append('config_reg_'+proj_name+'_MultiModal')\n",
    "        else:\n",
    "            MultiModal_list.append('config_cls_'+proj_name+'_MultiModal')\n",
    "    print(MultiModal_list)\n",
    "\n",
    "    for fname in MultiModal_list:\n",
    "\n",
    "        config_yaml = read_config(fname) \n",
    "        proj_name = config_yaml['Data']['label_name']\n",
    "\n",
    "        chosen_seed,chosen_fold = config_yaml['seed&fold']\n",
    "\n",
    "\n",
    "        if proj_name in ['pfs','os']:\n",
    "            mode = 'mean'\n",
    "            print(f'{proj_name}')\n",
    "        else:\n",
    "            mode = 'best'\n",
    "            if proj_name == 'hazard_level':\n",
    "                print(f'Risk Group')\n",
    "            elif proj_name == 'p36':\n",
    "                print(f'1p36')\n",
    "            elif proj_name == 'q23':\n",
    "                print(f'11q23')\n",
    "            else:\n",
    "                print(f'{proj_name}')\n",
    "\n",
    "\n",
    "\n",
    "        output_dir = os.path.join(csv_dir,proj_name)\n",
    "        # os.makedirs(output_dir,exist_ok=True)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # device = torch.device(\"cpu\")\n",
    "        num_gpus = 1\n",
    "        dist = False \n",
    "        original_csv = os.path.join(csv_dir,config_yaml['Data']['label_name']+'.csv')   \n",
    "        print(original_csv)\n",
    "\n",
    "\n",
    "        test_df = pd.read_csv(original_csv) \n",
    "        test_df['case_id'] = test_df['case_id'].astype(str) \n",
    "        \n",
    "\n",
    "        if test_df[str(proj_name)].nunique() == 1:\n",
    "            print(f\"{proj_name} There is only one category, cannot calculate auc/cindex\")\n",
    "            continue\n",
    "\n",
    "        patient_files = {}\n",
    "        for index, row in test_df.iterrows():\n",
    "            case_id = row['case_id'] \n",
    "            if case_id not in patient_files:\n",
    "                patient_files[case_id] = []\n",
    "            patient_files[case_id].append(row['filename']) \n",
    "\n",
    "        feature_dict = {}\n",
    "        for file_name in test_df['filename']:\n",
    "            file_path = '/home/huruizhen/多尺度特征/images_multisacle_2048/'+file_name\n",
    "            feature_dict[file_name[:-len('.pt')]]=file_path\n",
    "\n",
    "        # print(feature_dict)\n",
    "\n",
    "        patient_files = {str(k): [feature_dict[i[:-len('.pt')]] for i in v] for k, v in patient_files.items()} \n",
    "\n",
    "\n",
    "        patient_feature_vision = {case_id: [torch.load(file_name,map_location=device).unsqueeze(0).float() for file_name in file_list] for case_id, file_list in patient_files.items()}   \n",
    "        # print(type(patient_feature_vision.keys()))\n",
    "\n",
    "        test_df.drop_duplicates(subset=['case_id'], inplace=True)  \n",
    "        test_df.reset_index(drop=True, inplace=True)  \n",
    "        test_df['case_id'] = test_df['case_id'].astype(str)  \n",
    "\n",
    "        \n",
    "        if config_yaml['Data']['label_name'] in ['os','pfs']:\n",
    "            all_labels = torch.tensor(test_df[config_yaml['Data']['label_name']].values)\n",
    "            all_status = torch.tensor(test_df['status'].values)\n",
    "            all_case_id_label = {case_id : (torch.tensor(test_df[test_df['case_id']==case_id][config_yaml['Data']['label_name']].tolist()),torch.tensor(test_df[test_df['case_id']==case_id]['status'].tolist())) for case_id,feature_list in patient_feature_vision.items()}\n",
    "        else:\n",
    "            all_labels = torch.tensor(test_df[config_yaml['Data']['label_name']].values) \n",
    "            all_case_id_label = {case_id : torch.tensor(test_df[test_df['case_id']==case_id][config_yaml['Data']['label_name']].tolist()) for case_id,feature_list in patient_feature_vision.items()}\n",
    "\n",
    "        patient_feature_report = {str(case_id):torch.load('/home/huruizhen/mil_dataset_1024/reports_1024/'+str(case_id)+'.pt',map_location=device).unsqueeze(dim=0).float() for case_id in test_df['case_id']}\n",
    "\n",
    "        assert len(patient_feature_vision.keys())==len(patient_feature_report.keys())\n",
    "        # if len(patient_feature_report.keys())<=5:\n",
    "        #     print(f'The number of case_ids in the independent test set of this class is too small:{len(patient_feature_report.keys())}')\n",
    "        #     continue\n",
    "\n",
    "\n",
    "        seed_list = [42,184,762,381,493,526,307, 648, 255, 739]\n",
    "        # 每个病人的所有feature的logits取平均\n",
    "        for seed in seed_list:\n",
    "            if seed != chosen_seed:\n",
    "                continue\n",
    "\n",
    "            wts_dir = f\"/home/huruizhen/mil/workspace/2048维度/多模态/动态权重/模型/{fname}/{proj_name}/seed{seed}/\"\n",
    "\n",
    "            save_path = f\"/home/huruizhen/mil/workspace/独立测试集/测试集性能/\"\n",
    "            with torch.inference_mode():\n",
    "                model = MILModel(config_yaml, save_path=str(save_path)).to(device)  # 定义模型  使用了 pytorch_lighting\n",
    "\n",
    "                criterion = get_obj_from_str(config_yaml[\"Loss\"][\"name\"])(**config_yaml[\"Loss\"][\"params\"])\n",
    "\n",
    "                case_id_logits={}\n",
    "                metric = []\n",
    "                for i in range(5):\n",
    "                    if i != chosen_fold:\n",
    "                        continue\n",
    "\n",
    "                    wts_path = os.path.join(wts_dir, f\"fold_{i}/fold_{i}.pth\")\n",
    "                    wts = torch.load(wts_path)\n",
    "\n",
    "\n",
    "                    model.load_state_dict(wts,strict=True)\n",
    "\n",
    "                    for case_id,feature_list_vision in patient_feature_vision.items():\n",
    "                        case_id = str(case_id)\n",
    "                        if case_id not in patient_feature_report:\n",
    "                            print(f\"{case_id}Not in the patient's pathological report\")\n",
    "                            print(patient_feature_report)\n",
    "                        feature_report = patient_feature_report[case_id].to(device)\n",
    "                        # print(feature_report.shape)\n",
    "                        logits = []\n",
    "                        for feature_vision in feature_list_vision:\n",
    "                            feature_vision = feature_vision.to(device)\n",
    "\n",
    "                            with torch.inference_mode():  \n",
    "                                logit, results_dict = model((feature_vision,feature_report))\n",
    "\n",
    "                            logits.append(logit)\n",
    "\n",
    "\n",
    "                        if mode == 'mean':\n",
    "                            case_id_logits[case_id]=torch.cat(logits,dim=0).mean(dim=0,keepdim=True)  \n",
    "                        if mode == 'best':\n",
    "                            case_id_logits[case_id] = logits[0]\n",
    "                            best_logit = logits[0]\n",
    "                            if config_yaml['Data']['label_name'] in ['os','pfs']:\n",
    "                                label,status = all_case_id_label[case_id]\n",
    "                                label = label.long().to(device)\n",
    "                                status = status.long().to(device)\n",
    "                                criterion = CoxSurvLoss()\n",
    "                                best_crossentropy = criterion(logits[0].float(),label,status)\n",
    "                                for logit in logits[1:]:\n",
    "                                    crossentropy = criterion(logit,label,status)\n",
    "                                    if crossentropy <= best_crossentropy:\n",
    "                                        case_id_logits[case_id] = logit\n",
    "                            else:\n",
    "                                label = all_case_id_label[case_id].long().to(device)\n",
    "\n",
    "                                criterion = nn.CrossEntropyLoss()\n",
    "                                best_crossentropy = criterion(logits[0].float(),label)\n",
    "                                for logit in logits[1:]:\n",
    "                                    crossentropy = criterion(logit,label)\n",
    "                                    if crossentropy <= best_crossentropy:\n",
    "                                        case_id_logits[case_id] = logit\n",
    "                        \n",
    "                    all_logits = torch.cat([logits for case_id,logits in case_id_logits.items()],dim = 0)\n",
    "                    \n",
    "                    if config_yaml['Data']['label_name'] in ['os','pfs']:\n",
    "                        risks_list = all_logits\n",
    "                        labels_list = all_labels\n",
    "                        status_list = all_status\n",
    "                        c_index =float(round(compute_c_index(risks_list, labels_list, status_list),4))\n",
    "                        p_value = float(round(compute_P_value(risks_list, labels_list, status_list),4))\n",
    "                        print(f'c_index:{c_index},p_value:{p_value}')\n",
    "                        metric.append(c_index)\n",
    "                        bootstrap_cindex_mean, ci_lower, ci_upper, cindex_std, cindex_values = bootstrap_cindex(risks_list, labels_list, status_list)\n",
    "                        print(f'bootstrap_cindex_mean & CI:\\n{bootstrap_cindex_mean:.4f} ({ci_lower:.4f}--{ci_upper:.4f}), {p_value}\\n')\n",
    "\n",
    "                    else:\n",
    "                        auc = float(round(calculate_auc(all_logits, all_labels), 4))\n",
    "                        \n",
    "                        # print(f'auc:{auc}')\n",
    "                        metric.append(auc)\n",
    "                        all_probs = torch.softmax(all_logits, dim=1)\n",
    "                        print(f\"all_labels: {all_labels.shape}, all_probs: {all_probs.shape}\")\n",
    "                        bootstrap_auc_mean, ci_lower, ci_upper, auc_std, auc_values = bootstrap_auc(all_labels, all_probs)\n",
    "                        print(f'bootstrap_auc_mean & CI:\\n{bootstrap_auc_mean:.4f} ({ci_lower:.4f}--{ci_upper:.4f})\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
